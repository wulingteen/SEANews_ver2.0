# LLM æ¨ç†éç¨‹æµå¼é¡¯ç¤ºåŠŸèƒ½

## åŠŸèƒ½æ¦‚è¿°

å•Ÿç”¨ GPT-5.2 çš„æ¨ç†åŠŸèƒ½ï¼ˆReasoning Token Supportï¼‰ï¼Œå°‡ LLM åœ¨å›è¦†å‰çš„æ€è€ƒéç¨‹å³æ™‚æµå¼å‚³è¼¸åˆ°å‰ç«¯èŠå¤©è¨Šæ¯æ¡†é¡¯ç¤ºã€‚

## æŠ€è¡“å¯¦ç¾

### 1. å¾Œç«¯ä¿®æ”¹ (server/agno_api.py)

#### å•Ÿç”¨æ¨ç†æ‘˜è¦
```python
# é»˜èªå•Ÿç”¨æ¨ç†æ‘˜è¦ï¼ˆauto = æœ€è©³ç´°ï¼‰
DEFAULT_REASONING_SUMMARY = os.getenv("OPENAI_REASONING_SUMMARY", "auto").strip()
```

#### å¢å¼·æ¨ç†æ–‡æœ¬æå–
```python
def extract_reasoning_text(event: Any) -> Optional[str]:
    """æå–æ¨ç†éç¨‹æ–‡æœ¬ï¼Œæ”¯æ´ï¼š
    1. reasoning_summary å±¬æ€§
    2. Responses API çš„ reasoning è¼¸å‡ºé …ç›®
    3. å‚³çµ± reasoning äº‹ä»¶ï¼ˆreasoning_started, reasoning_step ç­‰ï¼‰
    """
```

#### æ·»åŠ æ¨ç†äº‹ä»¶è™•ç†
```python
def build_routing_update(event: Any, routing_state: Dict[str, str]):
    # æ¨ç†äº‹ä»¶ â†’ éœ€æ±‚åˆ†æéšæ®µï¼ˆæ€è€ƒä¸­ï¼‰
    if event_name in {
        "ReasoningStarted", "TeamReasoningStarted",
        "ReasoningStep", "TeamReasoningStep",
        "ReasoningContentDelta", "TeamReasoningContentDelta"
    }:
        return {"id": "reasoning-thinking", "label": "AI æ€è€ƒä¸­", 
                "status": "running", "stage": "analyze"}
```

#### SSE æµå¼æ¨é€æ¨ç†å…§å®¹
```python
# å³æ™‚æ¨é€æ¨ç†æ‘˜è¦åˆ°å‰ç«¯
reasoning_text = extract_reasoning_text(event)
if reasoning_text:
    reasoning_fragments.append(reasoning_text)
    print(f"ğŸ§  [æ¨ç†æ¨é€] ç™¼é€æ¨ç†å…§å®¹åˆ°å‰ç«¯")
    yield f"data: {json.dumps({{'reasoning_chunk': reasoning_text}})}\n\n"
```

### 2. å‰ç«¯ä¿®æ”¹ (src/App.jsx)

#### æ¥æ”¶æ¨ç†æµå¼æ•¸æ“š
```javascript
// è™•ç†å³æ™‚æ¨ç†éç¨‹ï¼ˆæµå¼æ¨é€ï¼‰
if (parsed.reasoning_chunk) {
    setReasoningSummary((prev) => {
        const updated = prev + parsed.reasoning_chunk;
        console.log('ğŸ§  [æ¨ç†æµ] ç´¯ç©æ¨ç†å…§å®¹:', updated.slice(0, 100) + '...');
        return updated;
    });
    continue;
}
```

#### èŠå¤©è¨Šæ¯æ¡†é¡¯ç¤ºæ¨ç†æ°£æ³¡
```jsx
{/* å³æ™‚é¡¯ç¤ºæ¨ç†éç¨‹ï¼ˆæ€è€ƒæ°£æ³¡ï¼‰ */}
{isLoading && reasoningSummary && (
    <div className="message is-assistant is-thinking">
        <div className="message-avatar">ğŸ§ </div>
        <div className="message-bubble reasoning-bubble">
            <div className="message-meta">
                <span className="message-name">AI æ€è€ƒéç¨‹</span>
                <span className="message-time">{nowTime()}</span>
            </div>
            <div className="reasoning-content">
                <ReactMarkdown remarkPlugins={[remarkGfm]}>
                    {reasoningSummary}
                </ReactMarkdown>
            </div>
        </div>
    </div>
)}
```

### 3. æ¨£å¼å„ªåŒ– (src/styles.css)

#### æ¨ç†æ°£æ³¡æ¨£å¼
```css
/* ç´«è‰²æ¼¸è®ŠèƒŒæ™¯ï¼Œå€åˆ¥æ–¼æ™®é€šå›è¦† */
.message.is-thinking .message-bubble {
    background: linear-gradient(135deg, rgba(168, 85, 247, 0.1), rgba(139, 92, 246, 0.08));
    border: 1px solid rgba(168, 85, 247, 0.25);
    box-shadow: 0 4px 12px rgba(168, 85, 247, 0.1);
}

/* é ­åƒè„ˆè¡å‹•ç•« */
.message.is-thinking .message-avatar {
    background: linear-gradient(135deg, #a855f7, #8b5cf6);
    animation: thinking-pulse 2s ease-in-out infinite;
}
```

#### æ‰“å­—æ¸¸æ¨™å‹•ç•«
```css
.typing-cursor {
    display: inline-block;
    background: var(--accent);
    animation: blink 1s step-end infinite;
}
```

## ç’°å¢ƒè®Šæ•¸é…ç½®

åœ¨ `.env` æ–‡ä»¶ä¸­æ·»åŠ ï¼š

```env
# OpenAI æ¨ç†è¨­ç½®ï¼ˆGPT-5.2 æ”¯æŒï¼‰
OPENAI_REASONING_EFFORT=medium     # none/minimal/low/medium/high/xhigh
OPENAI_REASONING_SUMMARY=auto      # auto/concise/detailedï¼ˆauto = æœ€è©³ç´°ï¼‰
OPENAI_USE_RESPONSES=1             # ä½¿ç”¨ Responses APIï¼ˆå¿…é ˆï¼‰
```

## GPT-5.2 æ¨ç†æ”¯æŒ

æ ¹æ“š OpenAI æ–‡æª”ï¼š

- **Reasoning token support**: âœ… æ”¯æŒ
- **Context window**: 400,000 tokens
- **Max output tokens**: 128,000 tokensï¼ˆåŒ…å«æ¨ç† tokensï¼‰
- **API æ”¯æŒ**:
  - Chat Completions API: `reasoning_effort` åƒæ•¸
  - Responses API: `reasoning.summary` åƒæ•¸ï¼ˆæ¨è–¦ï¼‰

## ä½¿ç”¨å ´æ™¯

1. **éœ€æ±‚åˆ†æéšæ®µ**: é¡¯ç¤º LLM å¦‚ä½•ç†è§£ç”¨æˆ¶æŒ‡ç¤º
2. **ä»»å‹™è·¯ç”±åˆ¤æ–·**: å±•ç¤ºç‚ºä»€éº¼é¸æ“‡ simple/full æ¨¡å¼
3. **æ–°èæœå°‹**: èªªæ˜æœå°‹ç­–ç•¥å’Œé—œéµè©é¸æ“‡
4. **å…§å®¹è™•ç†**: è§£é‡‹å¦‚ä½•è§£æå’Œçµ„ç¹”æ–°èå…§å®¹

## å¯¦æ™‚æµç¨‹

```
ç”¨æˆ¶æäº¤ â†’ é¡¯ç¤º"AI æ€è€ƒä¸­"æ°£æ³¡ï¼ˆç´«è‰²ï¼‰ â†’ æµå¼æ¨é€æ¨ç†å…§å®¹ 
â†’ æ¨ç†å®Œæˆ â†’ é¡¯ç¤ºæœ€çµ‚å›è¦†ï¼ˆæ©™è‰²ï¼‰ â†’ æ¨ç†æ°£æ³¡æ¶ˆå¤±
```

## å„ªå‹¢

1. **é€æ˜åº¦**: ç”¨æˆ¶å¯è¦‹ AI çš„æ€è€ƒéç¨‹
2. **ä¿¡ä»»åº¦**: ç†è§£ AI çš„æ±ºç­–é‚è¼¯
3. **èª¿è©¦**: ä¾¿æ–¼ç™¼ç¾æ¨ç†éŒ¯èª¤
4. **é«”é©—**: æ¸›å°‘ç­‰å¾…ç„¦æ…®ï¼ŒçŸ¥é“ AI åœ¨åšä»€éº¼

## æ€§èƒ½è€ƒé‡

- æ¨ç† tokens æœƒå¢åŠ  API æˆæœ¬ï¼ˆæŒ‰ output tokens è¨ˆè²»ï¼‰
- `reasoning_effort=high` å¯èƒ½ç”¢ç”Ÿæ•¸åƒ tokens
- å»ºè­°ç”Ÿç”¢ç’°å¢ƒä½¿ç”¨ `medium` æˆ–æ ¹æ“šä»»å‹™è¤‡é›œåº¦å‹•æ…‹èª¿æ•´
- å¯é€šé `max_output_tokens` é™åˆ¶ç¸½ token æ•¸

## æ¸¬è©¦é©—è­‰

1. å•Ÿå‹•å¾Œç«¯: `python server/agno_api.py`
2. å•Ÿå‹•å‰ç«¯: `npm run dev`
3. æäº¤æ–°èæœå°‹è«‹æ±‚
4. è§€å¯ŸèŠå¤©æ¡†ä¸­çš„ç´«è‰²"AI æ€è€ƒéç¨‹"æ°£æ³¡
5. æª¢æŸ¥å¾Œç«¯æ—¥èªŒä¸­çš„ `ğŸ§  [æ¨ç†æ¨é€]` æ¨™è¨˜

## æ•…éšœæ’é™¤

### æ²’æœ‰é¡¯ç¤ºæ¨ç†éç¨‹

1. æª¢æŸ¥ `.env` ä¸­ `OPENAI_REASONING_SUMMARY=auto`
2. ç¢ºèª `OPENAI_USE_RESPONSES=1`ï¼ˆResponses API å¿…é ˆï¼‰
3. æŸ¥çœ‹å¾Œç«¯æ—¥èªŒæ˜¯å¦æœ‰ `ğŸ§  [æ¨ç†æ¨é€]`
4. æª¢æŸ¥å‰ç«¯æ§åˆ¶å°æ˜¯å¦æœ‰ `ğŸ§  [æ¨ç†æµ]`

### é›²ç«¯èˆ‡æœ¬æ©Ÿè¡Œç‚ºä¸ä¸€è‡´

- é›²ç«¯å¯èƒ½å› ç¶²è·¯å»¶é²å°è‡´äº‹ä»¶é †åºä¸åŒ
- æ¨ç†äº‹ä»¶å¯èƒ½å…ˆæ–¼å…¶ä»–äº‹ä»¶åˆ°é”
- å‰ç«¯æœƒç´¯ç©æ‰€æœ‰æ¨ç†ç‰‡æ®µï¼Œæœ€çµ‚é¡¯ç¤ºå®Œæ•´å…§å®¹

## åƒè€ƒè³‡æ–™

- [OpenAI Reasoning Models](https://platform.openai.com/docs/guides/reasoning)
- [GPT-5.2 Model Card](https://platform.openai.com/docs/models/gpt-5.2)
- [Responses API](https://platform.openai.com/docs/api-reference/responses)
